num_inst = length(unique(data$Instructor))
date_start_bod <- min(data$Date)
date_stop_bod <- max(data$Date)
bod_cals <- sum(dt_comb$Calories)
bod_lbs <- round(bod_cals/3500,0)
total_workouts_tracked <- nrow(dt_comb)
max_hr <- round(mean(dt_comb$Max.HR),0)
avg_hr <- round(mean(dt_comb$Avg.HR),0) # closest whole number
date_start <- min(dt_comb$Date)
date_stop <- max(dt_comb$Date)
# visualize what percent of the workouts are Cardio vs Yoga
activity_type <- data %>% group_by(Activity.Type) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
activity_type$prop = round(100*(activity_type$workout_cnt/sum(activity_type$workout_cnt)),0)
# Compute the position of labels
activity_type <- activity_type %>%
arrange(workout_cnt) %>%
mutate(ypos = cumsum(prop)- 0.1*prop )
ggplot(activity_type, aes(x="", y=workout_cnt, fill=Activity.Type)) + geom_bar(stat="identity", width=1, color="white") + coord_polar("y", start=0) + theme_void() + geom_text(aes(y = ypos, label = paste(prop,'%')), color = "black", size=6) + labs(title = "Beachbody On-Demand Activity Type (%)")
# try the bar chart again but use a stacked viz to show the activty type per instructor
dt_inst_act <- data %>% group_by(Instructor, Activity.Type) %>% summarize(workout_cnt = n())
dt_inst_act <- dt_inst_act[order(dt_inst_act$workout_cnt, decreasing = TRUE),] # order decending by workout total count
# calculate a new column as the percent of total workouts
dt_inst_act$workout_pct = round(100*(dt_inst_act$workout_cnt/sum(dt_inst_act$workout_cnt)),0)
names(sum_inst)[names(sum_inst) == 'workout_cnt'] <- 'instructor_cnt' # rename to instructor count
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
dt_pgm[order(-dt_pgm$workout_cnt) %>% kbl() %>% kable_styling()
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
dt_pgm[order(-dt_pgm$workout_cnt),] %>% kbl() %>% kable_styling()
library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
dt_pgm[order(-dt_pgm$workout_cnt),] %>% kbl() %>% kable_styling()
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
dt_pgm[order(-dt_pgm$workout_cnt),] %>% kbl() %>% kable_styling(fixed_thead = T)
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
kbl(dt_pgm[order(-dt_pgm$workout_cnt),]) %>% kbl_paper() %>% scroll_box(height = "200px")
library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
kbl(dt_pgm[order(-dt_pgm$workout_cnt),]) %>% kable_paper() %>% scroll_box(height = "200px")
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
blogdown::serve_site()
#library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),])
#kbl(dt_pgm[order(-dt_pgm$workout_cnt),]) %>% kable_paper() %>% scroll_box(height = "200px")
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
#library(kableExtra)
# visualize what percent of the workouts are Cardio vs Yoga
dt_pgm <- data %>% group_by(Program, Instructor) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
dt_pgm$prop = round(100*(dt_pgm$workout_cnt/sum(dt_pgm$workout_cnt)),0)
#sort in descending order
ggplot(dt_pgm, aes(x=workout_cnt)) + geom_histogram(binwidth=1, color="black", fill = "steelblue") + labs(x = "Program count", title = "Distribution Workouts by Program")
#print(knitr::kable(dt_pgm[order(-dt_pgm$workout_cnt),]))
print(kbl(dt_pgm[order(-dt_pgm$workout_cnt),]) %>% kable_paper() %>% scroll_box(height = "200px"))
#kable(dt_pgm[order(-dt_pgm$workout_cnt),], "html") %>%
#    kable_styling() %>%
#    scroll_box(width = "500px", height = "200px")
tukey
library(agricolae)
anova <- aov(Avg.HR ~ Program, data = dt_comb)
#summary(anova)
# resource: https://r-graph-gallery.com/84-tukey-test.html
#tukey = TukeyHSD(x=anova, conf.level = 0.95)
#tukey
# agricolae library
# resource: https://rpubs.com/aaronsc32/post-hoc-analysis-tukey
tukey <- HSD.test(anova, trt='Program', alpha=0.06) # 0.05 alpha seemed too selective, grouping too many in 'ab'
#tukey
# vlookup the group assignment to the program
#boxplot(dt_comb$Avg.HR ~ dt_comb$Program , ylim=c(min(dt_comb$Avg.HR) , 1.1*max(dt_comb$Avg.HR)) , ylab="value" , main="") + coord_flip()
# col=my_colors[as.numeric(LABELS[,1])]
# Reference: http://rfunction.com/archives/1302
#ggplot(dt_comb, aes(x=Program, y = Avg.HR)) + geom_boxplot() + coord_flip() + labs(title = "Average HR by Program")
par(mar=c(5,12,4,1)+0.1, mpg=c(10,1,0)) # widen margin to fit program name labels mar=c(bottom, left, top, and right. )
# mpg=c((i.e. xlab and ylab in plot), the second the tick-mark labels, and third the tick marks.)
plot(tukey, horiz=TRUE, las=1) # las = 1 for horizontal tick mark labels
title( xlab="Avg.HR")
tukey
summary(tukey)
tukey
print(tukey)
blogdown::build_site()
blogdown::build_site()
blogdown:::serve_site()
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
dt_wk <- dt_wk(which[dt_wk$workout_cnt > 0],)
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
avg_workout_per_week
View(dt_wk)
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
# how many weeks had zero workouts?
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
avg_workout_per_week
no_wk_cnt
length(dt_wk)
length(dt_wk$Week)
dt_wk %>% group_by(workout_cnt)
dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
dt_wk_hist <- dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
dt_wk_hist
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
dt_wk_hist <- dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
dt_wk_cnt
dt_wk_cnt
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
dt_wk_hist <- dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
dt_wk_hist
no_wk_cnt
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
dt_wk_hist <- dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
#dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
View(dt_wk)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# install.packages("ggplot2")
library(ggplot2)
#install.packages("dplyr")
library(dplyr)
#Read the data file in .csv format and convert Date column data type to datetime:
data <- read.csv(file = "C:/Users/17077/Documents/Health/Beachbody Workouts.csv") #Beachbody On-Demand (BOD)
# remove BOD rows without an instructor
data <- data[-which(data$Instructor == ""), ]
# convert the Date column to the datetime data type
data$Date <- as.Date(data$Date, "%m/%d/%Y")
#data$Date <- format(data$Date,"%m/%d/%Y") # this changes it to a character
# rename the column 'Time..m.' to just 'Time' to make the code simpler
names(data)[names(data) == 'Time..m.'] <- 'Time'
# read in the garmin file
garmin <- read.csv(file = "C:/Users/17077/Documents/Health/Garmin_Activities.csv")
garmin$Calories <- strtoi(garmin$Calories)
names(garmin)[names(garmin) == 'Time'] <- 'Time.garmin'
garmin$Timediff <- round(as.numeric(as.difftime(garmin$Time.garmin, format = "%H:%M:%S")),1) # 	00:32:36
# only keep garmin data with activity type set to Cardio because those will be the ones that align to the BOD activities
dt_cardio <- garmin[which(garmin$Activity.Type == "Cardio"), c("Date", "Calories", "Avg.HR", "Max.HR", "Timediff")]
# convert the Date field type to be recognized as datetime data type, remove the time since we don't care about that
dt_cardio$Date <- as.Date(dt_cardio$Date, "%Y-%m-%d %H:%M:%S") # 2022-09-09 12:30:39
dt_cardio$Date <- format(dt_cardio$Date,"%m/%d/%Y") # converts back to a string
dt_cardio$Date <- as.Date(dt_cardio$Date, "%m/%d/%Y")
# inner join the two datasets based on date
dt_comb <- merge(dt_cardio, data[,c("Date","Program","Workout", "Description","Instructor", "Time", "Activity.Type")], by = "Date", all = TRUE) # outer join
# remove missing values that have BOD data by no watch data or vice versa
dt_comb <- na.omit(dt_comb, cols=c("Calories", "Program"))
dt_comb <- dt_comb[which(dt_comb$Activity.Type == "Cardio"),] # filter only to the cardio programs for this analysis
#dt_comb
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
# filter out weeks with zero workouts (sick or vacation weeks)
# how many weeks had zero workouts?
dt_wk_hist <- dt_wk %>% group_by(workout_cnt) %>% summarize(cnt = n())
no_wk_cnt <- length( dt_wk[which(dt_wk$workout_cnt == 0),])
#dt_wk <- dt_wk[which(dt_wk$workout_cnt > 0),]
#average number of workouts per week
avg_workout_per_week <- round(mean(dt_wk$workout_cnt),1)
# compute average calories burned per minute
dt_comb$cal_per_min = dt_comb$Calories / dt_comb$Timediff # both time and calories from the watch
avg_cal_per_min <- round(mean(dt_comb$cal_per_min),1)
# how many overall workouts did I do in the past year?
total_workouts <- nrow(data) # total number of workouts is equal to the total number of rows
# how many overall hours is this?
total_time = sum(data$Time)
total_time_h = round(total_time / 60,1)
num_progs = length(unique(data$Program))
num_inst = length(unique(data$Instructor))
date_start_bod <- min(data$Date)
date_stop_bod <- max(data$Date)
bod_cals <- sum(dt_comb$Calories)
bod_lbs <- round(bod_cals/3500,0)
total_workouts_tracked <- nrow(dt_comb)
max_hr <- round(mean(dt_comb$Max.HR),0)
avg_hr <- round(mean(dt_comb$Avg.HR),0) # closest whole number
date_start <- min(dt_comb$Date)
date_stop <- max(dt_comb$Date)
# look for inconsistencies between BOD Time and garmin's recorded Timediff
# add blue reference lines around +/- 10 minute
dt_comb %>% ggplot(aes(x = Time, y = Timediff)) + geom_point() + labs(x = "BOD time", y = "Garmin Time", title = "Garmin vs BOD workout length") +geom_abline(slope = 1, intercept = 1, color="grey") +  geom_abline(slope = 1, intercept = 10, color="blue", style="dashed") + geom_abline(slope = 1, intercept = -10, color="blue", style = "dashed")
# visualize what percent of the workouts are Cardio vs Yoga
activity_type <- data %>% group_by(Activity.Type) %>% summarize(workout_cnt = n())
# calculate as a percent (proportion)
activity_type$prop = round(100*(activity_type$workout_cnt/sum(activity_type$workout_cnt)),0)
# Compute the position of labels
activity_type <- activity_type %>%
arrange(workout_cnt) %>%
mutate(ypos = cumsum(prop)- 0.1*prop )
ggplot(activity_type, aes(x="", y=workout_cnt, fill=Activity.Type)) + geom_bar(stat="identity", width=1, color="white") + coord_polar("y", start=0) + theme_void() + geom_text(aes(y = ypos, label = paste(prop,'%')), color = "black", size=6) + labs(title = "Beachbody On-Demand Activity Type (%)")
# try the bar chart again but use a stacked viz to show the activty type per instructor
dt_inst_act <- data %>% group_by(Instructor, Activity.Type) %>% summarize(workout_cnt = n())
dt_inst_act <- dt_inst_act[order(dt_inst_act$workout_cnt, decreasing = TRUE),] # order decending by workout total count
# calculate a new column as the percent of total workouts
dt_inst_act$workout_pct = round(100*(dt_inst_act$workout_cnt/sum(dt_inst_act$workout_cnt)),0)
names(sum_inst)[names(sum_inst) == 'workout_cnt'] <- 'instructor_cnt' # rename to instructor count
sum_inst <- data %>% group_by(Instructor) %>% summarize(workout_cnt = n())
sum_inst <- sum_inst[order(sum_inst$workout_cnt, decreasing = TRUE),] # order descending
# calculate a new column as the percent of total workouts
sum_inst$workout_pct = round(100*(sum_inst$workout_cnt/sum(sum_inst$workout_cnt)),0)
names(sum_inst)[names(sum_inst) == 'workout_cnt'] <- 'instructor_cnt' # rename to instructor count
# try the bar chart again but use a stacked viz to show the activty type per instructor
dt_inst_act <- data %>% group_by(Instructor, Activity.Type) %>% summarize(workout_cnt = n())
dt_inst_act <- dt_inst_act[order(dt_inst_act$workout_cnt, decreasing = TRUE),] # order decending by workout total count
# calculate a new column as the percent of total workouts
dt_inst_act$workout_pct = round(100*(dt_inst_act$workout_cnt/sum(dt_inst_act$workout_cnt)),0)
dt_comb2 = merge(dt_inst_act, sum_inst[,c("Instructor","instructor_cnt")], by="Instructor")
#dt_comb2
# plot the bar chart ordered by value so that the instructor with the most workouts is listed first and so on
#dt_comb2 %>% ggplot(aes(x=fct_reorder(Instructor, instructor_cnt), y = workout_pct, fill = Activity.Type)) + geom_col(position="stack") +  #coord_flip() + labs(y = "% Workouts", x = "Instructor", title = "Workouts by Instructor") + geom_text(aes(Instructor, instructor_cnt, #label=instructor_cnt, fill=NULL), data = sum_inst)
# plot the x-axis using the workout percent of total, but label with the absolute number to put into context
ggplot(dt_comb2, aes(reorder(Instructor, instructor_cnt, sum), workout_pct, fill = Activity.Type)) +
geom_col() +
geom_text(
aes(label = instructor_cnt, group = Instructor),
stat = 'summary', fun = sum, vjust = 0, hjust=-.2) + coord_flip() +  labs(y = "% Workouts", x = "Instructor", title = "Workouts by Instructor")
no_wk_cnt
dt_wk_hist
data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
dt_wk <- data %>% group_by(Year, Week) %>% summarize(workout_cnt = n()) # pivot by year and week to estimate the
dt_wk
View(dt_wk)
length( dt_wk[which(dt_wk$workout_cnt == 0),])
dt_wk[which(dt_wk$workout_cnt == 0),]
View(data)
View(dt_comb)
dt_comb %>% group_by(Description) %>% summarize(avg_hr = mean(Avg.HR))
dt_hr_by_wko <- dt_comb %>% group_by(Description) %>% summarize(avg_hr = mean(Avg.HR))
dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = FALSE),]
dt_hr_by_wko
dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = TRUE),]
dt_hr_by_wko
dt_hr_by_wko <- dt_comb %>% group_by(Program, Description) %>% summarize(avg_hr = mean(Avg.HR))
dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = TRUE),]
dt_hr_by_wko
print(knitr::kable(dt_hr_by_wko[order(-dt_hr_by_wko$avg_hr),]))
# which workout, regardless of program, has the highest average heart rate?
dt_hr_by_wko <- dt_comb %>% group_by(Program, Description) %>% summarize(avg_hr = mean(Avg.HR))
dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = TRUE),]
print(knitr::kable(dt_hr_by_wko[order(-dt_hr_by_wko$avg_hr),]))
blogdown:::serve_site()
# which workout, regardless of program, has the highest average heart rate?
dt_hr_by_wko <- dt_comb %>% group_by(Program, Description) %>% summarize(avg_hr = mean(Avg.HR))
#dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = TRUE),]
print(knitr::kable(dt_hr_by_wko[order(-dt_hr_by_wko$avg_hr),]))
# which workout, regardless of program, has the highest average heart rate?
dt_hr_by_wko <- dt_comb %>% group_by(Program, Description) %>% summarize(avg_hr = max(Avg.HR))
#dt_hr_by_wko <- dt_hr_by_wko[order(dt_hr_by_wko$avg_hr, decreasing = TRUE),]
print(knitr::kable(dt_hr_by_wko[order(-dt_hr_by_wko$avg_hr),]))
blogdown:::serve_site()
blogdown::build_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown::build_site()
